---
title: "T13"
author: "_"
date: "2025-06-28"
output: html_document
---

Comencemos incluyendo los paquetes que usaremos en este script.

```{r}
library(car)
library(dplyr)
library(ggpubr)
library(psych)
```

Obtengamos los datos en formato ancho.

```{r}
datos <- read.csv2("EP09 Datos.csv")
```

Obtengamos la muestra y separémosla en los conjuntos de entrenamiento y prueba, teniendo el cuidado de fijar una semilla para su reproductibilidad.
```{r}
set.seed(1111)
datos <- datos |> filter(Gender == 1) |> select(-Gender) |> sample_n(100, replace = FALSE)
datos_entren <- datos[1:70, ]
datos_prueba <- datos[71:100, ]
```

Para este script de ejemplo, usaremos como variable respuesta los diámetros de las rodillas (Knees.diameter).

Corresponde seleccionar al azar 8 posibles variables predictoras de este conjunto, teniendo cuidado de no seleccionar la variable de respuesta.

```{r}
nombre_respuesta <- "Knees.diameter"
variables <- colnames(datos_entren)
i_respuesta <- which(variables == nombre_respuesta)
predictores <- sample(variables[-i_respuesta], 8, replace = FALSE)

cat("Predictores seleccionados al azar:\n")
cat(paste(predictores, collapse = "\n"))
```


Predictores seleccionados al azar:
Ankles.diameter
Calf.Maximum.Girth
Waist.Girth
Bitrochanteric.diameter
Ankle.Minimum.Girth
Hip.Girth
Biiliac.diameter
Age
Estos son los predictores seleccionados al azar para ser considerados en el modelo de regresión lineal múltiple que vamos a construir.

Para seleccionar una de las variables restantes para construir un modelo de regresión lineal simple (RLS), vamos a evaluar su correlación con la variable respuesta.

```{r}
datos_resto <- datos_entren |> select(!all_of(predictores))
i_respuesta_resto <- which(colnames(datos_resto) == nombre_respuesta)
correlacion <- cor(datos_resto[-i_respuesta_resto], y = datos_resto[[nombre_respuesta]])

cat("Correlación con la variable respuesta:\n")
print(correlacion)
```

Asumiendo que el mejor predictor para un modelo de RLS es aquella variable con mayor correlación (directa o inversa) con la variable de respuesta, podemos determinar fácilmente nuestro predictor.

```{r}
i_mejor <- which(correlacion == max(abs(correlacion)))
predictor <- rownames(correlacion)[i_mejor]

cat("Variable más correlacionada con la variable respuesta:", predictor, "\n")
```


Filtramos para quedarnos con las variables relevantes.


```{r}
datos_entren <- datos_entren |>
  select(all_of(c(predictor, predictores, nombre_respuesta)))

```
##Regresión lineal simple

Demos entonces una mirada a los datos.

```{r}
p1 <- ggscatter(datos_entren, x = predictor, y = nombre_respuesta,
                color = "steelblue", fill = "steelblue",
                add = "reg.line", add.params = list(color = "red"))
print(p1)

```


Este gráfico de dispersión parece mostrar una relación lineal positiva entre las variables.

Obtengamos el modelo de regresión lineal simple.

```{r}
fmla <- formula(paste(nombre_respuesta, predictor, sep = " ~ "))
rls <- lm(fmla, data = datos_entren)

cat("Modelo de regresión lineal simple:\n")
print(summary(rls))
```

Podemos ver que el modelo de RLS obtenido explica alrededor del 40%
 de la varianza en los datos y que es significativamente mejor que simplemente usar la media (F(1,68)=43,8; p<0,001).

Revisemos los gráficos de los residuos que genera el modelo.

```{r}
cat("Prueba de curvatura:\n")
```


```{r}
residualPlots(rls, type = "rstandard", terms = ~ 1, col = "steelblue", pch = 20, col.quad = "red")
```


Vemos que no hay un patrón identificable y que los residuos parecen repartirse de forma aleatoria arriba y abajo de la línea de regresión. La prueba de curvatura resultan no significativas, por lo que no podemos descartar que el diámetro de las muñecas se relaciona linealmente con el diámetro de las rodillas.

Si tuviéramos dudas, podemos confirmar la normalidad de los residuos con un histograma y usando una prueba de normalidad.

```{r}
h_res <- gghistogram(data.frame(Residuos = resid(rls)), x = "Residuos", bins = 11,
                     fill = "steelblue")
print(h_res)
```

```{r}
sw_res <- shapiro.test(resid(rls))
cat("Test de normalidad de los residuos del modelo de RLS:")
print(sw_res)
```

Si bien se observa cierta asimetría, no hay evidencia suficiente para descartar que los residuos siguen un comportamiento normal.

Confirmemos que la varianza de los residuos se mantienen constante.

```{r}
cat("Prueba de varianza del error no constante:\n")
ncvTest(rls)

```

No se puede descartar entonces que los residuos cumplan con la condición de homocedasticidad (χ(1)=0,720; p=0,396).

Revisemos que los residuos se comportan de manera independiente como siguiere su gráfico.



```{r}
cat("Independencia de los residuos\n")
print(durbinWatsonTest(rls))
```
Confirmamos que no es posible descartar que la condición de independencia no se esté cumpliendo en este modelo (D-W=2,004; p=0,972).

Evaluemos ahora las estadísticas de influencia del modelo de RLS obtenido.



```{r}
cat("Rango para 95% de los residuos studentizados: ")
cat("[", round(qt(0.05/2, nrow(datos_entren) - length(coef(rls)) - 1), 3), ", ", sep = "")
cat(round(qt(1-0.05/2, nrow(datos_entren) - length(coef(rls)) - 1), 3), "]\n", sep = "")
cat("Límite del apalancamiento:", round(2 * mean(hatvalues(rls)), 3), "\n")
cat("Límite de la distancia de Cook:", round(3 * mean(cooks.distance(rls)), 3), "\n")

rls_inf <- influencePlot(rls, id = list(n = 3))
```


```{r}
cat("\nCasos notorios para el modelo de RLS:\n")
print(rls_inf)
```

El procedimiento detecta 8 casos que podrían estar influyendo excesivamente en los coeficientes del modelo de RLS obtenido. Revisemos si podemos identificar si estos casos potencialmente problemáticos están distorsionando el modelo.



```{r}
crPlots(rls, ylim = c(-2.3, 3.3),
        col = "steelblue", pch = 20, col.lines = c("red", "steelblue"),
        smooth = list(smoother = loessLine, span = 1),
        id = list(method = "r", n = 8, cex = 0.7, location = "lr"))

```

Vemos que en realidad no parece haber un apalancamiento indebido de alguno de estos casos. Podríamos sospechar del caso 66, pero su potencial influencia parece contrarrestada por valores cercanos, pero por debajo de la línea de regresión. Para comprobar, podemos revisar cómo luce el modelo de RLS sin ese dato.



```{r}
rls2 <- lm(fmla, data = datos_entren[-66, ])
crPlots(rls2, ylim = c(-2.3, 3.3),
        col = "steelblue", pch = 20, col.lines = c("red", "steelblue"),
        smooth = list(smoother = loessLine, span = 1),
        id = list(method = "r", n = 8, cex = 0.7, location = "lr"))

```
Podemos ver que el nuevo modelo es prácticamente igual al original, por lo que no parece necesario quitar casos. Hagamos una conclusión entonces.

El modelo obtenido parece confiable, ya que genera residuos aleatorios y no es posible descartar que sigan una distribución normal, usando un predictor que muestra una relación lineal con la variable respuesta. Tampoco se identifican casos que estén ejerciendo demasiada influencia en el modelo.

Por otro lado, el modelo consigue una bondad de ajuste aceptable, pues explica alrededor del 40%
 de la variabilidad en la variable predicha, que es una reducción significativa (F(1;68)=43,8; p<0,001).


###Regresión lineal múltiple
Para cumplir con la instrucción 6, vamos a utilizar la estrategia de regresión escalonada implementada en la función step(). Para eso usaremos nuestro modelo de RLS como modelo mínimo, y como modelo máximo el que utiliza todos los predictores que seleccionamos anteriormente de forma aleatoria.

```{r}
rlm_max_text <- paste(c(predictor, predictores), collapse = " + ")
rlm_max_fmla <- formula(paste(nombre_respuesta, rlm_max_text, sep = " ~ "))
rlm_max <- lm(rlm_max_fmla, data = datos_entren)

rlm <- step(rls, scope = list(lower = rls, upper = rlm_max), direction = "both")

```

El modelo obtenido no cumple con lo solicitado en el enunciado, pues tiene un predictor más de lo permitido. Comencemos identificando un predictor para ser eliminado.



```{r}
drop1(rlm, test = "F")

```

Vemos que el menor cambio en AIC ocurre eliminando el predictor Ankle.Minimum.Girth, que lleva a un modelo equivalente en cuanto a variabilidad no explicada (F(1,62)=2,841;p=0,097). Quitemos esta variable.



```{r}
rlm <- update(rlm, . ~ . - Ankle.Minimum.Girth)

```

Evaluemos la confiabilidad del modelo de RLM conseguido. Comencemos revisando que no exista niveles inaceptables de multicolinealidad.


```{r}
cat("Factores de inflación de la varianza:\n")
print(vif(rlm))
cat("Estadísticos de tolerancia:\n")
print(1 / vif(rlm))

```

Vemos que, en general, solo hay indicios de multicolinealidad moderada, pues solo dos predictores presentan valores de inflación de la varianza sobre 4. Probablemente estas dos variables están correlacionadas. Eliminemos la que presenta el mayor valor.


```{r}
rlm <- update(rlm, . ~ . - Hip.Girth)

cat("Factores de inflación de la varianza:\n")
print(vif(rlm))
cat("Estadísticos de tolerancia:\n")
print(1 / vif(rlm))


```

Muy bien, hemos eliminado gran parte de la multicolinealidad presente en el modelo anterior manteniendo 4 predictores nuevos agregados al modelo de RLS creado anteriormente.

Revisemos los residuos que genera este modelo.



```{r}
cat("Prueba de curvatura:\n")
residualPlots(rlm, type = "rstandard", terms = ~ 1, col = "steelblue", pch = 20, col.quad = "red")

```

Se ve cierta curvatura, pero que podría deberse a falta de observaciones en la muestra con diámetros de rodillas bajo los 18 o sobre los 21,5 cm. En el rango entre estos valores, no se ve un patrón preocupante, aunque existe cierta tendencia a patrones por sobre la línea de regresión. La prueba de curvatura también apunta en este sentido.

Revisemos la normalidad de estos residuos.



```{r}
qq_res <- ggqqplot(data.frame(Residuos = resid(rlm)), x = "Residuos", color = "steelblue")
print(qq_res)


```


```{r}
sw_res <- shapiro.test(resid(rlm))
cat("Test de normalidad de los residuos del modelo de RLM:")
print(sw_res)

```

Vemos que los residuos parecen seguir una distribución normal, con algunos casos en el límite, pero que no son suficientes para permitir descartar que se cumple esta condición (W=0,982; p=0.413).

Ahora verifiquemos la varianza e independencia de los residuos.


```{r}
cat("Prueba de varianza del error no constante:\n")
ncvTest(rlm)

cat("\nIndependencia de los residuos\n")
print(durbinWatsonTest(rlm))

```

Con esto confirmamos que no es posible descartar que se están cumpliendo las condiciones de homogeneidad de la varianza (χ(1)=0,339; p=0,561) e independencia de los residuos (D-W=1,669; p=0,156).

Revisemos si existen relaciones aproximadamente lineales entre los predictores y la variable de interés.



```{r}
crPlots(rlm,
        col = "steelblue", pch = 20, col.lines=c("red", "steelblue"),
        smooth = list(smoother=loessLine, span = 1),
        id = list(method = "r", n = 3, cex = 0.7, location = "lr"))

```

Observamos que las relaciones parecen aproximadamente lineales, aunque alguna duda puede quedar con cómo se distribuyen los residuos al considerar la variable Waist.Girth (grosor de la cintura). También podemos notar que la recta de regresión parcial para este predictor tiene una pendiente muy baja, abriendo dudas de su aporte. Revisemos su contribución en relación a los otros predictores.



```{r}
cat("Modelo de RLM obtenido:\n")
print(summary(rlm))

```

Esto confirma que esta variable no aporta al modelo. Siguiendo el principio de parsimonia, es mejor que lo quitemos (y hacer una revisión rápida que nada se altera demasiado al introducir este cambio).


```{r}
rlm <- update(rlm, . ~ . - Waist.Girth)

cat("Modelo de RLM obtenido:\n")
print(summary(rlm))

cat("\nPrueba de curvatura:\n")
residualPlots(rlm, type = "rstandard", terms = ~ 1, col = "steelblue", pch = 20, col.quad = "red")

```



```{r}
cat("\nFactores de inflación de la varianza:\n")
print(vif(rlm))

cat("\nPrueba de varianza del error no constante:\n")
ncvTest(rlm)

cat("\nIndependencia de los residuos\n")
print(durbinWatsonTest(rlm))

```

El nuevo modelo más simple parece mantener el comportamiento del modelo anterior.

Revisemos ahora si existen casos demasiado influyentes utilizando el gráfico de influencia para identificarlos.



```{r}
cat("Rango para 95% de los residuos studentizados: ")
cat("[", round(qt(0.05/2, nrow(datos_entren) - length(coef(rls)) - 1), 3), ", ", sep = "")
cat(round(qt(1-0.05/2, nrow(datos_entren) - length(coef(rls)) - 1), 3), "]\n", sep = "")
cat("Límite del apalancamiento:", round(2 * mean(hatvalues(rlm)), 3), "\n")
cat("Límite de la distancia de Cook:", round(3 * mean(cooks.distance(rlm)), 3), "\n")

rlm_inf <- influencePlot(rlm, id = list(n = 3))

```



```{r}
cat("\nCasos notorios para el modelo de RLM:\n")
print(rlm_inf)

```

Y el gráfico marginal de los valores predichos (fitted) para evaluar su influencia en el modelo.



```{r}
id_inf <- mmp(rlm,
              col = "steelblue", pch = 20, col.line = c("steelblue", "red"),
              smooth = list(smoother=loessLine, span = 1),
              id = list(method = "r", n = 7, cex = 0.7, location = "lr"))

```

Vemos que, a pesar que los casos 4 y 66 curvan la tendencia de los datos hacia arriba, el modelo (línea roja segmentada) no parece estar visiblemente modificada por alguno de los casos notorios identificados.

Notemos que en la función que genera el gráfico marginal, mmp() o su equivalente marginalModelPlot(), usan el argumento col.line para indicar los colores de las curvas ajustadas, primero para la curva suavizada de los datos y el segundo para la curva del modelo. Sin embargo, la función crPlots() que genera los gráficos de residuos por componente utiliza el parámetro col.lines (plural) para este propósito, debiendo indicar primero el color para la curva del modelo y luego el color para la curva suavizada de los datos. ¡Qué falta de consistencia! Es el precio de construir bibliotecas en comunidad…

Finalmente, cometemos la bondad de ajuste que alcanza el modelo. Vemos que consigue una reducción significativa de la variabilidad aleatoria (F(4;65)=29,7; p<0,001), pues explica alrededor del 65% de la varianza de la variable de salida.

Con todo este análisis podemos dar la siguiente conclusión.
El modelo de RLM obtenido parece ser confiable, puesto que se ajusta bien a los datos observados, incluye predictores que muestran una relación lineal con la variable de respuesta, genera residuos que parecen seguir una distribución normal y sin problemas evidentes de heterocedasticidad o de dependencia entre ellos. Por otro lado, no hay casos que estén dominando el modelo.

###Comparación de los modelos
Vimos que el modelo de RLS construido logra explicar alrededor del 40%
 de la variabilidad en los datos, mientras que el RLM que tenemos logra explicar cerca del 65%
 . Confirmemos si esta es una mejora significativa en la bondad de ajuste.

```{r}
cat("Comparación de los modelos de RLS y RLM:\n")
print(anova(rls, rlm))

```

Confirmamos entonces que el modelo de RLM consigue una reducción significativa de la varianza no explicada en los datos con respecto al modelo de RLS (F(3,65)=15,623;p<0,001
).

Veamos si estos niveles de bondad de ajuste se reflejan en la calidad predictiva de los modelos conseguidos.

Como se indica en el enunciado, es importante hacer esta evaluación con datos distintos a los usados en la construcción de los modelos. Por esta razón hemos construido los modelos usando 70%
 de los datos disponibles, dejando el resto para hacer esta evaluación. Así, podemos comparar las predicciones que hacen con datos vistos (los de entrenamiento) y no vistos (los de prueba).

```{r}
rls_rmse_entre <- sqrt(mean(resid(rls) ** 2))
rls_preds <- predict(rls, datos_prueba)
rls_res_prueba <- datos_prueba[[nombre_respuesta]] - rls_preds
rls_rmse_prueba <- sqrt(mean(rls_res_prueba ** 2))
rls_pct_cambio <- ((rls_rmse_prueba - rls_rmse_entre) / rls_rmse_entre) * 100

rlm_rmse_entre <- sqrt(mean(resid(rlm) ** 2))
rlm_preds <- predict(rlm, datos_prueba)
rlm_res_prueba <- datos_prueba[[nombre_respuesta]] - rlm_preds
rlm_rmse_prueba <- sqrt(mean(rlm_res_prueba ** 2))
rlm_pct_cambio <- ((rlm_rmse_prueba - rlm_rmse_entre) / rlm_rmse_entre) * 100

cat(sprintf("Resumen de la variable de salida (%s):\n", nombre_respuesta))
print(describe(datos |> pull(all_of(nombre_respuesta)), skew = FALSE))
cat("\n")
cat("Rendimiento del modelo de RLS:\n")
cat(sprintf("RMSE para el conjunto de entrenamiento: %.3f\n", rls_rmse_entre))
cat(sprintf("RMSE para el conjunto de prueba: %.3f\n", rls_rmse_prueba))
cat(sprintf("Cambio en el error: %.1f%%\n", rls_pct_cambio))
cat("\n")
cat("Rendimiento del modelo de RLM:\n")
cat(sprintf("RMSE para el conjunto de entrenamiento: %.3f\n", rlm_rmse_entre))
cat(sprintf("RMSE para el conjunto de prueba: %.3f\n", rlm_rmse_prueba))
cat(sprintf("Cambio en el error: %.1f%%\n", rlm_pct_cambio))

```

Podemos observar que, efectivamente, el modelo de RLM obtiene menores tasas de error que el modelo de RLS. Sin embargo, esta disminución es más acentuada en los datos de entrenamiento y no se exhibe de igual magnitud en los de prueba. Por otro lado, un error de ±1,0 podría ser alto si se considera que el rango de la variable de salida (17,3–23,0) es de solo 5,7. Así, podemos concluir lo siguiente.

El modelo de RLM logra mejorar el rendimiento del modelo de RLS pero hay indicios de sobreajuste en él, ya que el error aumenta más de un 40%
 al pasar de datos vistos a datos no vistos. La calidad predictiva del modelo tampoco parece ser muy buena.

A pesar de que este modelo de RLM resultó confiable, parece tener problemas de generalización y calidad predictiva.

Lo que correspondería entonces es analizar la eliminación de uno o dos de los predictores y evaluar nuevamente la confiabilidad y el poder predictivo del nuevo modelo de RLM. Esto se deja como ejercicio.



Referencias
Heinz, G., Peterson, L. J., Johnson, R. W., & Kerk, C. J. (2003). Exploring relationships in body dimensions. Journal of Statistics Education, 11(2).