---
title: "Resumen_Lectura09"
output: html_document
---

# Lectura 09: Métodos contemporáneos para enfrentar datos problemáticos.
```{r, message=FALSE, warning=FALSE}
# Librerías
library(ggpubr)
library(WRS2)
library(dplyr)
library(tidyr)
```

## 1. Métodos Robustos
Tomando como ejemplo la prueba t de student, que se usa para inferir acerca de la media de una población. Se puede ver que esta medida de tendencia central tiene el problema de ser sensible a la presencia de valores atípicos, a distribuciones asimétricas o a muestras muy pequeñas. Lo que en términos generales puede generar los siguientes problemas:

- Resultados sesgados.
- Intervalos de confianza sub o sobreestimados.
- Reducción del poder estadístico de la prueba.

### 1.1. Alternativas robustas a la media
Entre las alternativas a la media, se encuentra la mediana, y en particular en esta sección, está la media truncada.
Esta es bastante similar a la media aritmética, con la diferencia de que se calcula descartando un determinado porcentaje (\( \gamma \)) de los valores en ambos extremos del conjunto de datos.

Otra alternativa es la media Winsorizada, que consiste en reemplazar los valores extremos por el valor más cercano que no sea extremo. Esto se puede hacer en R utilizando la función winmean(x: vector datos, tr: proporción a truncar).

## 2. Pruebas

### 2.1. Prueba Yuen para dos muestras independientes
Es una buena alternativa para la prueba t de Student para muestras independientes que trabaja con las medias truncadas y Winsorizadas en vez de las medias aritméticas. Por esto, son buenas para comparar dos medias independientes cuando los datos no cumplen la condición de normalidad, presentan datos atípicos, las varianzas son muy diferentes o los tamaños de las muestras son muy dispares.

#### Condiciones:
- Las observaciones en una muestra son independientes, esto significa que la elección de una observación no influye en la selección de otra para esa muestra.
- Las muestras son independientes, es decir que las observaciones de una muestra no están relacionadas con ninguna de las observaciones de la otra.
- Las variables estudiadas tienen al menos escala de intervalos iguales.

Sin embargo, hay otras condiciones que si bien no son obligatorias para aplicar el procedimiento, sí influyen en la calidad de las interpretaciones que podemos obtener:

- Las poblaciones de origen no son extremadamente diferentes (por ejemplo, una es muy sesgada a la derecha y la otra a la izquierda), por lo que comparar sus medias recortadas tiene sentido.
- El impacto de los valores extremos no es de interés de la investigación, pues la prueba de Yuen esencialmente ignora la información que estos valores entregan.
- El nivel de poda no está cerca del nivel de la mediana, siendo \( \gamma \approx \) 0.2 un valor frecuente.
- Las muestras no son demasiado reducidas, cuando la poda puede tener efectos perjudiciales. Como es usual, no existe un número fijo, pero algunos autores mencionan 5, 6 o 10 observaciones por cada muestra luego de la poda.

La prueba entonces, se basa en la estimación de la diferencia de las medias truncadas: \( d^t = \bar{x_1}^t - \bar{x_2}^t\), donde \( \bar{x_1}^t \) y \( \bar{x_2}^t \) son las medias truncadas de cada una de las muestras.

#### Hipótesis

- \( H_0: \mu_1^t = \mu_2^t \) (no hay diferencia entre las medias truncadas de las dos muestras).

- \( H_a: \mu_1^t \neq \mu_2^t \) (Existen diferencias entre las muestras truncadas).

#### Función en R
Se puede usar la función yuen(formula, data, tr) del paquete WRS2, donde:

- formula: tiene la forma <variable_dependiente> ~ <variable_independiente>. Note que la variable independiente debe tener dos niveles, a fin de determinar a qué muestra pertenece cada observación de la variable dependiente.
- data: matriz de datos.
- tr: parámetro \(\gamma\) de la poda.

#### Ejemplo
```{r}
# Matriz de datos
a <- c(25.1, 25.2, 25.3, 25.3, 25.4, 25.4, 25.5, 25.5, 25.6, 25.8, 25.8, 
       25.9, 25.9, 26.0, 26.0, 26.2, 26.2, 26.2, 26.3, 26.4, 26.5, 26.5, 
       26.6, 26.7, 26.7, 26.9, 26.9, 27.0, 27.1, 27.3, 27.8, 28.4, 28.5, 
       29.0, 29.8, 30.2, 31.8, 31.9, 33.3, 33.7)

b <- c(24.1, 24.4, 24.4, 24.5, 24.7, 24.8, 24.8, 25.1, 25.2, 25.2, 25.2, 
       25.3, 25.4, 25.7, 25.7, 26.3, 26.3, 26.4, 26.5, 27.2, 27.7, 28.3, 
       28.4, 28.4, 28.6, 28.7, 29.6, 29.9, 30.1, 30.5)

Tiempo <- c(a, b)
Algoritmo <- c(rep("A", length(a)), rep("B", length(b)))
datos <- data.frame(Tiempo, Algoritmo)

# Comprobar normalidad
qq <- ggqqplot(datos, x = "Tiempo", facet.by = "Algoritmo",
               palette = c("steelblue", "steelblue1"), color = "Algoritmo",
               xlab = "Cuantil teórico", ylab = "Tiempo de ejecución [ms]")

qq <- qq + theme(legend.position = "none")
print(qq)

# Aplicar poda al 20%
gamma <- 0.2
n_a <- length(a)
n_b <- length(b)
poda_a <- floor(n_a * gamma)
poda_b <- floor(n_b * gamma)

a_trunc <- a[poda_a:(n_a - poda_a)]
b_trunc <- b[poda_b:(n_b - poda_b)]

Tiempo_t <- c(a_trunc, b_trunc)
Algoritmo_t <- c(rep("A", length(a_trunc)), rep("B", length(b_trunc)))
datos_t <- data.frame(Tiempo_t, Algoritmo_t)

qq_t <- ggqqplot(datos_t, x = "Tiempo_t", facet.by = "Algoritmo_t",
               palette = c("steelblue", "steelblue1"), color = "Algoritmo_t",
               xlab = "Cuantil teórico", ylab = "Tiempo de ejecución truncado [ms]")
qq_t <- qq_t + theme(legend.position = "none")
print(qq_t)
```

También es posible usar la función pb2gen(formula, data, est, nboot), que usa bootstrapping para aplicar la prueba de Yuen usando otras medidas robustas de tendencia central, donde:

- formula: tiene la misma forma descrita para la prueba de Yuen.
- data: matriz de datos.
- est: medida a emplear. Puede tomar las opciones "mean" para la media y "median" para la mediana.
- nboot: cantidad de repeticiones bootstrap.

```{r}
# Aplicar prueba de Yuen
prueba <- yuen(Tiempo ~ Algoritmo, data = datos, tr = gamma)
print(prueba)

# Cantidad de repeticiones bootstrap
B <- 999

# Aplicar prueba de Yuen con bootstrap y la media
set.seed(135)
prueba_media <- pb2gen(Tiempo ~ Algoritmo, data = datos, est = "mean", nboot = B)

# Aplicar prueba de Yuen con bootstrap y la mediana
set.seed(135)
prueba_mediana <- pb2gen(Tiempo ~ Algoritmo, data = datos, est = "median", nboot = B)

# Mostrar los resultados
cat("\nPrueba Yuen con bootstrapping - Media\n")
print(prueba_media)
cat("\nPrueba Yuen con bootstrapping - Mediana\n")
print(prueba_mediana)
```

### 2.2. Prueba Yuen para muestras pareadas
Las suposiciones de esta prueba son:

- Los pares de observaciones son independientes, es decir, la elección de un par no influye en la selección de otro.
- La variable medida tiene al menos escala de intervalos iguales.

Como cuando se trabaja con muestras independientes, hay otras condiciones que afectan la calidad de esta versión de la prueba:

- Las diferencias siguen una distribución relativamente simétrica.
- La poda que se aplica elimina valores atípicos extremos.
- El nivel de poda no es cercano al nivel de la mediana.
- Las muestras no son demasiado reducidas. Algunos autores mencionan que se deberían tener al menos 10 o 15 pares de observaciones.

#### Hipótesis

- \( H_0: \mu_D^t = 0 \) (no hay diferencia entre las medias truncadas de las diferencias).
- \( H_a: \mu_D^t \neq 0 \) (existen diferencias entre las medias truncadas de las diferencias).

#### Función en R
Se puede usar la función yuend(x, y, tr) del paquete WRS2, donde:

- x: vector numérico con la primera muestra.
- y: vector numérico con la segunda muestra.
- tr: parámetro \(\gamma\) de la poda.

Como es de esperar, la función falla si los largos de los vectores x e y no coinciden.

#### Ejemplo
```{r}
# Construir las estructuras con los datos observados
a <- c(32.3, 32.0, 32.0, 36.0, 34.2, 32.7, 32.5, 32.0, 32.1, 33.4, 
       32.3, 37.2, 32.1, 32.0, 33.9, 34.1, 36.6, 34.5, 32.7, 33.1, 
       32.7, 32.1, 36.7, 32.2, 38.0)

b <- c(35.3, 20.1, 18.6, 46.3, 42.1, 39.3, 37.0, 28.0, 30.2, 40.4, 
       35.6, 50.7, 33.6, 17.9, 41.0, 41.6, 47.8, 43.2, 38.3, 39.9, 
       38.0, 28.3, 48.4, 34.7, 52.9)

dif <- a - b

# Aplicar una poda del 20% al conjunto de diferencias
gamma <- 0.2
n <- length(dif)
poda <- floor(n * gamma)
dif <- sort(dif)
dif_trunc <- dif[(poda + 1) : (n - poda)]
n_t <- length(dif_trunc)

# Obtener gráficos Q-Q de las diferencias originales y podadas
datos <- data.frame(Diferencia = c(dif, dif_trunc),
                    Muestra = c(rep("Original", n),rep("Podados", n_t)))
qq <- ggqqplot(datos, x = "Diferencia", facet.by = "Muestra",
               palette = c("steelblue", "steelblue1"), color = "Muestra",
               xlab = "Cuantil teórico",
               ylab = "Diferencias en tiempos\\nde ejecución [ms]")

qq <- qq + theme(legend.position = "none")
print(qq)

# Aplicar y mostrar la prueba de Yuen para muestras pareadas
gamma <- 0.2
prueba <- yuend(x = a, y = b, tr = gamma)
print(prueba)
```
### 2.3. Análisis robusto de una vía para muestras independientes
El paquete WRS2 ofrece diferentes alternativas a ANOVA de una vía para muestras independientes que podemos usar cuando los tamaños muestrales son muy diferentes o no se cumple la condición de homocedasticidad. Todas ellas asumen que:

- Las observaciones en una muestra son independientes, es decir que las observaciones se eligen sin considerar ninguna otra.
- Las muestras son independientes, es decir que las observaciones de una muestra no tienen ninguna relación con alguna de las observaciones en las otras muestras.
- Las variables estudiadas tienen al menos escala de intervalos iguales.

Sin embargo, también debemos tener en cuenta condiciones que afectan la calidad de la prueba, que son análogas a las mencionadas para la prueba de Yuen.

#### Hipótesis

- \( H_0: \mu_A = \mu_B = \mu_C \) (no hay diferencia entre las medias truncadas de las muestras).
- \( H_a: \exists i,j \in {A,B,C}, i \neq j | \mu_i \neq \mu_j \) (existe al menos una diferencia entre las medias truncadas de las muestras).

#### Funciones en R
La función t1way(formula, data, tr, alpha) efectúa un procedimiento similar a ANOVA usando medias truncadas. A su vez, la función lincon(formula, data, tr, alpha) permite realizar el procedimiento post-hoc correspondiente.

De manera similar, t1waybt(formula, data, tr, nboot) realiza un procedimiento análogo al anterior incorporando bootstrapping. En este caso el procedimiento post-hoc puede realizarse mediante la función mcppb20(formula, data, tr, nboot). Los argumentos asociados a las funciones mencionadas son:

- formula: de la forma <variable_dependiente> ~ <variable_independiente>.
- data: matriz de datos.
- tr: parámetro \(\gamma\) de la poda.
- alpha: nivel de significancia.
- nboot: cantidad de repeticiones bootstrap.

#### Ejemplo
```{r}
# Construir las estructuras con los datos
A <- c(25.1, 25.2, 25.3, 25.3, 25.4, 25.4, 25.5, 25.5, 25.6, 25.8, 25.8, 
       25.9, 25.9, 26.0, 26.0, 26.2, 26.2, 26.2, 26.3, 26.4, 26.5, 26.5, 
       26.6, 26.7, 26.7, 26.9, 26.9, 27.0, 27.1, 27.3, 27.8, 28.4, 28.5, 
       29.0, 29.8, 30.2, 31.8, 31.9, 33.3, 33.7)

B <- c(24.1, 24.4, 24.4, 24.5, 24.7, 24.8, 24.8, 25.1, 25.2, 25.2, 25.2, 
       25.3, 25.4, 25.7, 25.7, 26.3, 26.3, 26.4, 26.5, 27.2, 27.7, 28.3, 
       28.4, 28.4, 28.6, 28.7, 29.6, 29.9, 30.1, 30.5)

C <- c(24.5, 24.5, 24.5, 24.5, 24.5, 24.5, 24.6, 24.6, 24.6, 24.6, 24.6, 
       24.6, 24.7, 24.7, 24.7, 24.7, 24.8, 25.0, 25.0, 25.0, 25.2, 25.2, 
       25.2, 25.2, 25.5, 25.7, 25.9, 26.2, 26.5, 26.5, 26.7, 27.0, 29.2, 
       29.9, 30.1)

Tiempo <- c(A, B, C)
Algoritmo <- c(rep("A", length(A)), rep("B", length(B)), rep("C", length(C)))
Algoritmo <- factor(Algoritmo)
datos <- data.frame(Tiempo, Algoritmo)

# Obtener gráficos Q-Q de las muestras
qq <- ggqqplot(datos, x = "Tiempo", facet.by = "Algoritmo", color = "Algoritmo",
               palette = c("steelblue", "steelblue1", "steelblue4"),
               xlab = "Cuantil teórico", ylab = "Tiempos\\nde ejecución [ms]")
qq <- qq + theme(legend.position = "none")
print(qq)

# Fijar nivel de significación, nivel de poda y nro. de iteraciones bootstrap
alfa <- 0.05
gamma <- 0.2
nboot <- 999

#------------------------------------#
#--------- Medias Truncadas ---------#
#------------------------------------#

# Comparar los diferentes algoritmos usando medias truncadas
set.seed(666)
una_via <- t1way(Tiempo ~ Algoritmo, data = datos,
                 tr = gamma, alpha = alfa, nboot = nboot)

cat("Análisis de una vía para muestras independientes (asimptótico)\n")
cat("--------------------------------------------------------------\n")
print(una_via)

if(una_via[["p.value"]] < alfa) {
  una_via_ph <- lincon(Tiempo ~ Algoritmo, data = datos,
                       tr = gamma, alpha = alfa)
  
  cat("Análisis post-hoc para muestras independientes (asimptótico)\n")
  cat("------------------------------------------------------------\n")
  print(una_via_ph)
}

#-----------------------------------#
#------------ Bootstrap ------------#
#-----------------------------------#

# Comparar los diferentes algoritmos usando medias truncadas y bootstrapping
set.seed(666)
una_via_bt <- t1waybt(Tiempo ~ Algoritmo, data = datos,
                      tr = gamma, nboot = nboot)

cat("Análisis de una vía para muestras independientes (bootstrap)\n")
cat("------------------------------------------------------------\n")
print(una_via_bt)

if(una_via_bt[["p.value"]] < alfa) {
  set.seed(666)
  una_via_bt_ph <- mcppb20(Tiempo ~ Algoritmo, data = datos,
                           tr = gamma, nboot = nboot)
  
  cat("Análisis post-hoc para muestras independientes (bootstrap)\n")
  cat("----------------------------------------------------------\n")
  print(una_via_bt_ph)
}

```

### 2.4. Análisis robusto de una vía para muestras correlacionadas
El paquete WRS2 también ofrece alternativas a ANOVA de una vía para muestras correlacionadas, que son útiles cuando los datos violan la condición de normalidad o de esfericidad. Estos procedimientos asumen las siguientes condiciones:

- Los casos o bloques medidos son independientes entre sí.
- Se tiene un conjunto de mediciones (usualmente mayor a dos) para cada caso o bloque.
- La variable medida tiene al menos escala de intervalos iguales.

También debemos tener en cuenta condiciones que afectan la calidad de la prueba, que son análogas a las mencionadas para la prueba de Yuen con muestras apareadas.

#### Hipótesis

- \( H_0:\) Sean A, B, C, las muestras a evaluar, entonces: \( \mu_\text{(A-B)} = \mu_\text{(A-C)} = \mu_\text{(B-C)} = 0\).
- \( H_a:\) Existen al menos dos muestras que presentan diferencias, es decir: \( \exists A_i,A_j \in {A,B,C}, i \neq j | \mu_\text{(A_i - A_j)} \neq 0 \).

#### Funciones en R
Existe la función rmanova(y, groups, blocks, tr) que efectúa un procedimiento similar a ANOVA usando medias truncadas, mientras que la función rmmcp(y, groups, blocks, tr, alpha) implementa el procedimiento post-hoc para dicha prueba. Por otra parte, rmanovab(y, groups, blocks, tr, alpha) realiza la misma tarea que rmanova(), incorporando bootstrapping. En este caso, el procedimiento post-hoc está dado por la función pairdepb(y, groups, blocks, tr, nboot). Los argumentos para esta familia de funciones son:

- formula: de la forma <variable_dependiente> ~ <variable_independiente>.
- y: vector con la variable dependiente.
- groups: vector que indica las medidas repetidas.
- blocks: vector que identifica los casos o bloques.
- tr: parámetro \(\gamma\) de la poda.
- alpha: nivel de significancia.
- nboot: cantidad de repeticiones bootstrap.

#### Ejemplo
```{r}
# Construir las estructuras con los datos
A <- c(32.0, 32.0, 32.0, 32.0, 32.1, 32.1, 32.1, 32.2, 32.3, 32.3, 32.5, 
       32.7, 32.7, 32.7, 33.1, 33.4, 33.9, 34.1, 34.2, 34.5, 36.0, 36.6, 
       36.7, 37.2, 38.0)

B <- c(33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.3, 33.3, 33.3, 33.3, 33.5, 
       33.6, 33.7, 33.9, 33.9, 34.2, 34.2, 34.3, 34.3, 34.4, 34.5, 34.6, 
       36.4, 38.9, 40.2)

C <- c(32.0, 32.2, 32.5, 32.6, 32.7, 32.7, 32.7, 33.0, 33.2, 33.4, 33.6, 
       33.6, 33.9, 34.1, 34.2, 34.4, 34.4, 34.5, 34.6, 34.7, 36.3, 36.6, 
       36.7, 38.9, 39.2)

Instancia <- factor(1:length(A))
datos_anchos <- data.frame(Instancia, A, B, C)
dif_anchos <- data.frame(A_B = A - B, A_C = A - C, B_C = B - C)

# Llevar las matrices de datos a formato largo
datos <- datos_anchos |>
  pivot_longer(c("A", "B", "C"), names_to = "Algoritmo", values_to = "Tiempo") |>
  mutate(Algoritmo = factor(Algoritmo))

dif <- dif_anchos |>
  pivot_longer(everything(), names_to = "Algoritmos", values_to = "Diferencia") |>
  mutate(Algoritmos = factor(Algoritmos))

# Obtener gráficos Q-Q de las diferencias
qq <- ggqqplot(dif, x = "Diferencia", facet.by = "Algoritmos",
               color = "Algoritmos",
               palette = c("steelblue", "steelblue1", "steelblue4"),
               xlab = "Cuantil teórico",
               ylab = "Diferencias en tiempos\\nde ejecución [ms]")
qq <- qq + theme(legend.position = "none")
print(qq)

#------------------------------------#
#--------- Medias Truncadas ---------#
#------------------------------------#

# Fijar nivel de significación y nivel de poda
alfa <- 0.05
gamma <- 0.2

# Comparar los algoritmos usando medias truncadas de las diferencias
mr_rob <- rmanova(y = datos[["Tiempo"]], groups = datos[["Algoritmo"]],
                  blocks = datos[["Instancia"]], tr = gamma)

cat("Análisis de una vía para medidas repetidas (asimptótico)\n")
cat("--------------------------------------------------------\n")
print(mr_rob)

if(mr_rob[["p.value"]] < alfa) {
  mr_rob_ph <- rmmcp(y = datos[["Tiempo"]], groups = datos[["Algoritmo"]],
                     blocks = datos[["Instancia"]], tr = gamma, alpha = alfa)
  
  cat("Análisis post-hoc para medidas repetidas (asimptótico)\n")
  cat("------------------------------------------------------\n")
  print(mr_rob_ph)
}

#-----------------------------------#
#------------ Bootstrap ------------#
#-----------------------------------#

# Fijar la cantidad de iteraciones bootstrap
nboot <- 999

# Comparar los algoritmos usando diferencias truncadas y bootstrapping
set.seed(666)
mr_bt <- rmanovab(y = datos[["Tiempo"]], groups = datos[["Algoritmo"]],
                  blocks = datos[["Instancia"]], tr = gamma, nboot = nboot)

cat("Análisis de una vía para medidas repetidas (bootstrapped)\n")
cat("---------------------------------------------------------\n")
print(mr_bt)

if(mr_bt[["test"]] > mr_bt[["crit"]]) {
  set.seed(666)
  mr_bt_ph <- pairdepb(y = datos[["Tiempo"]], groups = datos[["Algoritmo"]],
                       blocks = datos[["Instancia"]], tr = gamma, nboot = nboot)
  
  cat("Análisis post-hoc para medidas repetidas (bootstrapped)\n")
  cat("-------------------------------------------------------\n")
  print(mr_bt_ph)
}
```

## 3. Remuestreo
Los métodos basados en remuestreo son una buena alternativa a emplear cuando necesitamos inferir sobre parámetros distintos a la media o la proporción, o bien cuando no se cumplen los supuestos sobre la distribución de los datos (Como normalidad u homocedasticidad) o el conocimiento de parámetros poblacionales (como la varianza) que hacen las pruebas paramétricas estudiadas.

La idea básica del remuestreo es extraer repetidamente muestras desde un conjunto original de datos observados para obtener información sobre la población de la que provienen. A estas muestras de la muestra original se les conoce como remuestras.

Sin embargo, aunque el remuestreo relaja muchas condiciones paramétricas, no está libre de supuestos:

- La muestra original es representativa de la población, que es fundamental para que las estadísticas obtenidas con las remuestras sean válidas. Si la muestra original está sesgada, las remuestras también lo estarán.
- Las observaciones dentro de la muestra original son independientes.

### 3.1. Bootstrapping

Técnica de remuestreo no paramétrica utilizada para inferir propiedades de una población a partir de una muestra, utíl cuando los datos no cumplen con el suepuesto de normalidad o cuando el tamaño de la muestra es pequeño.

Se utiliza si los datos son asimétricos, tienen valores atípicos o no siguen una distribución normal.

Reemplaza pruebas como la t de Student o ANOVA, que requieren normalidad y homocedasticidad.

- Se generan múltiples remuestras a partir de la muestra original, seleccionando observaciones al azar con reposición. Una misma observación puede aparecer múltiples veces en una remuestra.

-Para cada remuestra se calcula el estadístico de interés (media, mediana diferencia de medias).

- La colección de estos estadísticos forma la distribucción bootstrap, que aproxima la distribución muestral del estadístico.

-La destribución de bootstrap permite estimar:

  - Intervalos de confianza: ejemplo, usando percentiles (2.5% y 97.5% para un IC del 95%) 
  - Sesgo: Diferencia entre la media de la distribución bootstrap y el estadístico original.
  - Error estándar: Desviación estándar de la distribución bootstrap.


Ventajas de bootstrapping:
- No requiere supuestos distribucionales.
- Útil para muestras pequeñas o estadísticos complejos.
- Flexible: Puede aplicarse a medianas, varianzas, correlaciones, etc.

Limitaciones:
- Requiere potencia computacional (miles de remuestras).
- La muestra original debe ser representativa de la población.
- No funciona bien para datos con dependencia.

Ejemplo:

```{r}
# Cargar la librería boot (si no está instalada: install.packages("boot"))
library(boot)

# 1. Crear una muestra de ejemplo (datos no normales con outliers)
set.seed(123)
muestra <- c(rnorm(30, mean = 50, sd = 10),  # Datos "normales"
             120, 130)                        # Outliers artificiales

# Ver histograma de la muestra original
hist(muestra, main = "Distribución de la muestra original", col = "lightblue")

# 2. Función para calcular la media en remuestras bootstrap
media <- function(data, i) {
  mean(data[i])  # i son los índices de la remuestra
}

# 3. Generar distribución bootstrap (2000 remuestras)
set.seed(432)
resultados <- boot(data = muestra, statistic = media, R = 2000)

# Ver resultados básicos
print(resultados)

# 4. Calcular intervalo de confianza BCa (bias-corrected and accelerated)
intervalo_bca <- boot.ci(resultados, type = "bca")
print(intervalo_bca)

# 5. Visualizar la distribución bootstrap
plot(resultados)
```
Analisis:
Original: Media calculada de la muestra original.

bias: Sesgo de la estimación bootstrap respecto al valor original
En este caso: La media de las remuestras bootstrap es 0.13 unidades menor que la media original, lo que sugiere un sesgo mínimo 

std. error: Error estándar de la distribución bootstrap.

Método BCa:
Ajusta por sesgo (bias) y asimetría (skewness) en la distribución bootstrap, siendo más preciso que los intervalos percentiles simples.

Interpretación:
Con un 95% de confianza, la media poblacional verdadera se encuentra entre 49.05 y 65.09.

Ahora con es
```{r}
library(bootES)
# Fijar semilla para reproducibilidad
set.seed(123)
alfa = 0.05

# Ejecutar bootstrap del efecto
distribucion_bES <- bootES(
  muestra,
  R = 2000,                    # Número de repeticiones bootstrap
  ci.type = "bca",          # Tipo de intervalo de confianza: BCa
  ci.conf = 1 - alfa,       # Nivel de confianza (por ejemplo, 0.95)
  plot = TRUE               # Mostrar gráfico
)

# Mostrar resultados del bootstrap
print(distribucion_bES)
```


Diferencia con pruebas de permutaciones:
Bootstrapping: Muestreo con reposición para estimar propiedades de la población.

Permutaciones: Reordenamiento sin reposición para probar hipótesis.


Bootstrap para dos muestras:
Es ideal para lo mismo que de una muestra, pero ahora queremos comparar estadísticos de dos muestras.

Muestras no apareadas
```{r}
library(boot)

# Datos de ejemplo (tiempos de ejecución en ms)
grupo_A <- c(25, 30, 28, 35, 40)
grupo_B <- c(20, 22, 18, 25, 30)

# Función para calcular la diferencia de medias
diff_means <- function(data, indices) {
  muestra_A <- data[indices, 1]
  muestra_B <- data[indices, 2]
  return(mean(muestra_A) - mean(muestra_B))
}

# Preparar datos (columnas para cada grupo)
datos <- data.frame(A = grupo_A, B = grupo_B)

# Bootstrapping (2000 remuestras)
set.seed(432)
resultados <- boot(data = datos, statistic = diff_means, R = 2000)

# Intervalo de confianza BCa
boot.ci(resultados, type = "bca")

# Valor p (prueba bilateral)
diferencia_obs <- mean(grupo_A) - mean(grupo_B)
diferencia_boot <- resultados$t
p_value <- (sum(abs(diferencia_boot) >= abs(diferencia_obs)) + 1) / (2001)
cat("Valor p:", p_value)

```
Si valor p < 0.05 se rechaza Ho de medias iguales

Muestras apareadas

```{r}
# Datos apareados (ej: antes y después)
antes <- c(10, 12, 15, 9, 11)
despues <- c(8, 10, 12, 7, 10)

# Función para la media de las diferencias
media_diferencias <- function(data, indices) {
  muestra <- data[indices, ]
  return(mean(muestra$despues - muestra$antes))
}

# Bootstrapping
datos <- data.frame(antes, despues)
resultados <- boot(data = datos, statistic = media_diferencias, R = 2000)
boot.ci(resultados, type = "bca")

```

Otros:

Prueba Yuen con Bootstrapping:

Uso: Comparar medias truncadas (robustas a outliers) entre dos grupos.

Función en R:

```{r}
library(WRS2)

# Datos de ejemplo (similar a la Sección 12.1.3 del PDF)
datos <- data.frame(
  Tiempo = c(25.1, 25.2, 25.3, 33.7, 30.2, 24.1, 24.5, 30.5),  # Tiempos en ms
  Grupo = c(rep("A", 5), rep("B", 3))  # 5 observaciones para A, 3 para B
)

# Aplicar pb2gen con bootstrapping (2000 remuestras)
set.seed(123)
resultado <- pb2gen(formula = Tiempo ~ Grupo, data = datos, est = "mean", nboot = 2000)

# Ver resultados
print(resultado)
```
Analisis:
Test statistic:  Es una medida estandarizada de la diferencia entre las medias de los grupos, ajustada por el error estándar robusto (similar a un t-statistic pero con métodos robustos).

p>0.05 → No hay evidencia suficiente para rechazar Ho .

Intervalo: El intervalo incluye el 0 (diferencia nula), lo que respalda la conclusión del valor p.

Significado práctico: La diferencia real entre las medias podría ser desde -3.28 unidades (Grupo B mayor que A) hasta +5.67 unidades (Grupo A mayor que B)


### Permutación
Las pruebas de permutaciones son métodos no paramétricos para contrastar hipótesis, especialmente útiles cuando:

- Los datos no cumplen supuestos de normalidad o homocedasticidad.

- Las muestras son pequeñas.

- Quieres una alternativa exacta a pruebas como t-test o ANOVA.


Definición: Reordenamiento aleatorio de las observaciones entre grupos, asumiendo que bajo Ho no hay diferencias.

Objetivo: Generar una distribución nula del estadístico (ej: diferencia de medias) para calcular valores p exactos.

Muestras independientes:
```{r}
library(ggpubr)

# Datos de ejemplo (tiempos de ejecución en ms)
grupo_A <- c(25, 30, 28, 35, 40)
grupo_B <- c(20, 22, 18, 25, 30)

# Función para calcular diferencia de medias
calcular_diferencia <- function(muestra_1, muestra_2) {
  mean(muestra_1) - mean(muestra_2)
}

# Estadístico observado
diferencia_obs <- calcular_diferencia(grupo_A, grupo_B)

# Permutaciones
set.seed(131)
R <- 9999  # Número de permutaciones
diferencias <- replicate(R, {
  todos_los_datos <- c(grupo_A, grupo_B)
  permutacion <- sample(todos_los_datos, replace = FALSE)
  nueva_A <- permutacion[1:length(grupo_A)]
  nueva_B <- permutacion[(length(grupo_A) + 1):length(todos_los_datos)]
  calcular_diferencia(nueva_A, nueva_B)
})

# Valor p (bilateral)
valor_p <- (sum(abs(diferencias) >= abs(diferencia_obs)) + 1) / (R + 1)
cat("Diferencia observada:", diferencia_obs, "\nValor p:", valor_p)
```
Si p < 0.05 se rechaza Ho, por tanto las medias difieren significativamente

Muestras Apareadas:

```{r}
antes <- c(10, 12, 15, 9, 11)
despues <- c(8, 10, 12, 7, 10)

# Estadístico observado (media de las diferencias)
dif_obs <- mean(despues - antes)

# Permutaciones (intercambio aleatorio de signos)
R <- 9999
dif_perm <- replicate(R, {
  signos <- sample(c(-1, 1), length(antes), replace = TRUE)
  mean((despues - antes) * signos)
})

# Valor p
valor_p <- (sum(abs(dif_perm) >= abs(dif_obs)) + 1) / (R + 1)
cat("Valor p:", valor_p)
```
